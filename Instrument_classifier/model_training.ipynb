{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ae7az5HV7gUW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling3D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.models import load_model\n",
    "#from kt_utils import *\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "osjZHUkR7gUf"
   },
   "outputs": [],
   "source": [
    "input_shape_ = [101, 108, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "colab_type": "code",
    "id": "X31DhRuw7ogL",
    "outputId": "2f745b2f-d46b-4c49-e6d4-f212c9f1314a"
   },
   "outputs": [],
   "source": [
    "#!pip install -U -q PyDrive\n",
    "#from pydrive.auth import GoogleAuth\n",
    "#from pydrive.drive import GoogleDrive\n",
    "#from google.colab import auth\n",
    "#from oauth2client.client import GoogleCredentials\n",
    "# Authenticate and create the PyDrive client.\n",
    "#auth.authenticate_user()\n",
    "#gauth = GoogleAuth()\n",
    "#gauth.credentials = GoogleCredentials.get_application_default()\n",
    "#drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "s0uEEeoF8Fq1",
    "outputId": "6ebf67a8-5c48-43d3-ee00-ceaecce8e712"
   },
   "outputs": [],
   "source": [
    "#link = 'https://drive.google.com/open?id=1ph8OBd6RffqmCXxjjAPgb6PX2jKcB2JF'\n",
    "#fluff, id = link.split('=')\n",
    "#print (id) # Verify that you have everything after '='\n",
    "#downloaded = drive.CreateFile({'id':id}) \n",
    "#downloaded.GetContentFile('X_accordion.npy')\n",
    "X_accordion = np.load('X_accordion.npy')\n",
    "\n",
    "#link = 'https://drive.google.com/open?id=1uLUGKZepXealNHcgE-oH22hyFQd_EVL1'\n",
    "#fluff, id = link.split('=')\n",
    "#print (id) # Verify that you have everything after '='\n",
    "#downloaded = drive.CreateFile({'id':id}) \n",
    "#downloaded.GetContentFile('Y_accordion.npy')\n",
    "Y_accordion = np.load('Y_accordion.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "W64zsMJ28Vtg",
    "outputId": "1e6424b8-1dba-4d1b-fe1a-df0aa1ea02e3"
   },
   "outputs": [],
   "source": [
    "#link = 'https://drive.google.com/open?id=1GYwito9726CA56kKYjNyIid5OpWibpIp'\n",
    "#fluff, id = link.split('=')\n",
    "#print (id) # Verify that you have everything after '='\n",
    "#downloaded = drive.CreateFile({'id':id}) \n",
    "#downloaded.GetContentFile('X_piano.npy')\n",
    "X_piano = np.load('X_piano.npy')\n",
    "\n",
    "#link = 'https://drive.google.com/open?id=1VfTNBm3HyaSEaoUuOjC4LyoESrOvtcm4'\n",
    "#fluff, id = link.split('=')\n",
    "#print (id) # Verify that you have everything after '='\n",
    "#downloaded = drive.CreateFile({'id':id}) \n",
    "#downloaded.GetContentFile('Y_piano.npy')\n",
    "Y_piano = np.load('Y_piano.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "rLhsajwg8qFB",
    "outputId": "5912840f-8528-4b0c-93a0-a2a7806259c0"
   },
   "outputs": [],
   "source": [
    "#link = 'https://drive.google.com/open?id=1StsGt8xABBQmLUmyds3oSjcKVBLkaHdA'\n",
    "#fluff, id = link.split('=')\n",
    "#print (id) # Verify that you have everything after '='\n",
    "#downloaded = drive.CreateFile({'id':id}) \n",
    "#downloaded.GetContentFile('X_violin.npy')\n",
    "X_violin = np.load('X_violin.npy')\n",
    "\n",
    "#link = 'https://drive.google.com/open?id=1arptg0ukDIBqpIWkdvl9BpWGskBenHVA'\n",
    "#fluff, id = link.split('=')\n",
    "#print (id) # Verify that you have everything after '='\n",
    "#downloaded = drive.CreateFile({'id':id}) \n",
    "#downloaded.GetContentFile('Y_violin.npy')  \n",
    "Y_violin = np.load('Y_violin.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "D2S4paeV8skL",
    "outputId": "4823f35d-dd83-4f32-8916-c6c513a48c2c"
   },
   "outputs": [],
   "source": [
    "#link = 'https://drive.google.com/open?id=1LqyzrUElRD6QAXYc8CRKiYRtzFFoEhc2'\n",
    "#fluff, id = link.split('=')\n",
    "#print (id) # Verify that you have everything after '='\n",
    "#downloaded = drive.CreateFile({'id':id}) \n",
    "#downloaded.GetContentFile('X_guitar.npy')  \n",
    "X_guitar = np.load('X_guitar.npy')\n",
    "\n",
    "#link = 'https://drive.google.com/open?id=1_u5kzFCitEqslNF0lMW9IeJpwl0zDodG'\n",
    "#fluff, id = link.split('=')\n",
    "#print (id) # Verify that you have everything after '='\n",
    "#downloaded = drive.CreateFile({'id':id}) \n",
    "#downloaded.GetContentFile('Y_guitar.npy')\n",
    "Y_guitar = np.load('Y_guitar.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "JjDyXLNh8xDJ",
    "outputId": "f3b32c02-7994-4afe-da15-4cdc568f6777"
   },
   "outputs": [],
   "source": [
    "#link = 'https://drive.google.com/open?id=1ikjxpQt04Alcl9lTatZa49HxIJYIm1OD'\n",
    "#fluff, id = link.split('=')\n",
    "#print (id) # Verify that you have everything after '='\n",
    "#downloaded = drive.CreateFile({'id':id}) \n",
    "#downloaded.GetContentFile('X_noise.npy')\n",
    "X_noise = np.load('X_noise.npy')\n",
    "\n",
    "#link = 'https://drive.google.com/open?id=1v_SjZaHsvcNmI0CodMcabd5-iyKLBeOm'\n",
    "#fluff, id = link.split('=')\n",
    "#print (id) # Verify that you have everything after '='\n",
    "#downloaded = drive.CreateFile({'id':id}) \n",
    "#downloaded.GetContentFile('Y_noise.npy')\n",
    "Y_noise = np.load('Y_noise.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q4-OnwLk9lFV"
   },
   "outputs": [],
   "source": [
    "X = np.concatenate((X_accordion, X_piano, X_violin, X_guitar, X_noise),axis=0)\n",
    "Y = np.concatenate((Y_accordion, Y_piano, Y_violin, Y_guitar, Y_noise),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "1p9AyKM1OK2e",
    "outputId": "f56911d2-7ef6-4cd9-f430-e96c549d9ea7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57504, 101, 108)\n",
      "(57504, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pFXcourz9lZS"
   },
   "outputs": [],
   "source": [
    "indices = np.arange(Y.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "X = X[indices]\n",
    "Y = Y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DC15Kh7M7gUl"
   },
   "outputs": [],
   "source": [
    "X_train_orig = X[0:50000]\n",
    "Y_train = Y[0:50000]\n",
    "X_test_orig = X[50000:57504]\n",
    "Y_test = Y[50000:57504]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HwRVcN167gUq"
   },
   "outputs": [],
   "source": [
    "maxElement = np.amax(X_train_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16462066.603519555\n"
     ]
    }
   ],
   "source": [
    "print(maxElement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WC7PKTm-7gUs"
   },
   "outputs": [],
   "source": [
    "# Normalize image vectors\n",
    "X_train = X_train_orig/maxElement\n",
    "X_test = X_test_orig/maxElement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q0Ph6Igw7gUv"
   },
   "outputs": [],
   "source": [
    "train_shape = list(X_train.shape)\n",
    "train_shape.append(1)\n",
    "X_train = X_train.reshape(train_shape)\n",
    "\n",
    "test_shape = list(X_test.shape)\n",
    "test_shape.append(1)\n",
    "X_test = X_test.reshape(test_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mt1dKtGf7gUx"
   },
   "outputs": [],
   "source": [
    "def Detector(input_shape = input_shape_):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Feel free to use the suggested outline in the text above to get started, and run through the whole\n",
    "    # exercise (including the later portions of this notebook) once. The come back also try out other\n",
    "    # network architectures as well. \n",
    "        # Define the input placeholder as a tensor with shape input_shape. Think of this as your input image!\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding: pads the border of X_input with zeroes\n",
    "    X = ZeroPadding2D((1, 1))(X_input)\n",
    "    X = Conv2D(32, (3, 3), strides=(1, 1), name='conv0_0')(X)\n",
    "    #X = BatchNormalization(axis=3, name='bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = ZeroPadding2D((1, 1))(X_input)\n",
    "    X = Conv2D(32, (3, 3), strides=(1, 1), name='conv0_1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((3, 3), name='max_pool_0')(X)    \n",
    "    X = Dropout(0.25)(X)\n",
    "    \n",
    "    X = ZeroPadding2D((1, 1))(X_input)\n",
    "    X = Conv2D(64, (3, 3), strides=(1, 1), name='conv1_0')(X)\n",
    "    #X = BatchNormalization(axis=3, name='bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = ZeroPadding2D((1, 1))(X_input)\n",
    "    X = Conv2D(64, (3, 3), strides=(1, 1), name='conv1_1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((3, 3), name='max_pool_1')(X)    \n",
    "    X = Dropout(0.25)(X)\n",
    "\n",
    "    X = Conv2D(128, (3, 3), strides=(1, 1), name='conv2_0')(X)\n",
    "    #X = BatchNormalization(axis=3, name='bn0')(X)\n",
    "    X = Activation('relu')(X)    \n",
    "    X = Conv2D(128, (3, 3), strides=(1, 1), name='conv2_1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Global MAXPOOL\n",
    "    #X = GlobalMaxPooling2D(data_format=None)(X) \n",
    "    \n",
    "    # MAXPOOL\n",
    "    #X = MaxPooling2D((3, 3), name='max_pool_2')(X)    \n",
    "    #X = Dropout(0.25)(X)\n",
    "    \n",
    "    # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1024, activation=None, name='fc_1024')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Dropout(0.5)(X)    \n",
    "    X = Dense(5, activation='softmax', name='fc_3')(X)\n",
    "\n",
    "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
    "    model = Model(inputs=X_input, outputs=X, name='Detector')\n",
    "\n",
    "    return model\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nuyMUrP17gU0"
   },
   "outputs": [],
   "source": [
    "detector = Detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w_0jym7f7gU2"
   },
   "outputs": [],
   "source": [
    "detector.compile('adam', 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qcst4yzY7gU3"
   },
   "outputs": [],
   "source": [
    "filepath=\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sLYwiJAi7gU5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "50000/50000 [==============================] - 2013s 40ms/step - loss: 0.2393 - acc: 0.8959\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:434: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 2001s 40ms/step - loss: 0.2124 - acc: 0.9078\n",
      "Epoch 3/40\n",
      " 4000/50000 [=>............................] - ETA: 30:36 - loss: 0.1918 - acc: 0.9192"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-f5ecb514de5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "detector.fit(X_train, Y_train, epochs=40, batch_size=50, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8DNHxbhV7gU7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7504/7504 [==============================] - 45s 6ms/step\n",
      "\n",
      "Loss = 0.17789896140728934\n",
      "Test Accuracy = 0.9228144931132352\n"
     ]
    }
   ],
   "source": [
    "preds = detector.evaluate(X_test, Y_test, batch_size=32, verbose=1, sample_weight=None)\n",
    "\n",
    "print()\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z0JXm9vjQVdf"
   },
   "outputs": [],
   "source": [
    "detector.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "model_training.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
